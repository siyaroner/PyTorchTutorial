{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKrSSax2QoPq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self,in_channel,out_channel):\n",
        "      super(DoubleConv,self).__init__()\n",
        "      \n",
        "      self.conv=nn.Sequential(\n",
        "          nn.Conv2d(in_channels=in_channel,out_channels=out_channel,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "          nn.BatchNorm2d(out_channel),\n",
        "          nn.ReLU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(in_channels=out_channel,out_channels=out_channel,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "          nn.BatchNorm2d(out_channel),\n",
        "          nn.ReLU(inplace=True),\n",
        "          )\n",
        "\n",
        "  def forward(self,x):\n",
        "      return self.conv(x)\n",
        "# class Down(nn.Module):\n",
        "#   def __init__(self,in_channel,out_channel,mid_channel=None):\n",
        "#     super().__init__()\n",
        "#     self.doubleConv=DoubleConv(in_channel=in_channel,out_channel=out_channel,mid_channel=mid_channel)\n",
        "#     self.maxPool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "#   def forward(self,x):\n",
        "#       x=self.doubleConv(x)\n",
        "#       return self.MaxPool(x)\n",
        "\n",
        "# class Up(nn.Module):\n",
        "#   def __init__(self,in_channel,out_channel):\n",
        "#     super().__init__()\n",
        "#     self.deConv=nn.ConvTranspose2d(in_channels=in_channel,out_channels=in_channel//2,kernel_size=2,stride=2)\n",
        "    # self.doubleConv=DoubleConv(in_channel=in_channel,out_channel=out_channel)\n",
        "\n",
        "  # def forward(self,x,x_skip):\n",
        "  #     x=self.deConv(x)\n",
        "  #     x=torch.cat((x,x_skip),dim=1)\n",
        "  #     return self.doubleConv(x)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "  def __init__(self,in_channels=3,out_channels=1,features=[64,128,256,512]):\n",
        "    super(Unet,self).__init__()\n",
        "    self.ups=nn.ModuleList()\n",
        "    self.downs=nn.ModuleList()\n",
        "    self.pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    #self.inc=DoubleConv(in_channel,64)\n",
        "    #self.down1=Down(64,128)\n",
        "    #self.down2=Down(128,256)\n",
        "    #self.down3=Down(256,512)\n",
        "    #self.down4=Down(512,1024)\n",
        "\n",
        "    #self.up1=Up(1024,512)\n",
        "    #self.up2=Up(512,256)\n",
        "    #self.up3=Up(256,128)\n",
        "    #self.up4=Up(128,64)\n",
        "\n",
        "    #self.conv=nn.Conv2d(64,num_class,kernel_size=1)\n",
        "\n",
        "    #Down part of Unet\n",
        "\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channels,feature))\n",
        "      in_channels=feature\n",
        "    \n",
        "\n",
        "    #Ups part of Unet\n",
        "    for feature in reversed(features):\n",
        "        self.ups.append(\n",
        "            nn.ConvTranspose2d(feature*2,feature,kernel_size=2,stride=2))\n",
        "        self.ups.append(DoubleConv(feature*2,feature))\n",
        "\n",
        "    self.bottleneck=DoubleConv(features[-1],features[-1]*2)\n",
        "    self.final_conv=nn.Conv2d(features[0],out_channels,kernel_size=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    skip_connections=[]\n",
        "\n",
        "    for down in self.downs:\n",
        "      x=down(x)\n",
        "      skip_connections.append(x)\n",
        "      x=self.pool(x)\n",
        "    x=self.bottleneck(x)\n",
        "    skip_connections=skip_connections[::-1]\n",
        "    for idx in range(0,len(self.ups),2):\n",
        "      x=self.ups[idx](x)\n",
        "      skip_connection=skip_connections[idx//2]\n",
        "      if x.shape!=skip_connection.shape:\n",
        "        x=TF.resize(x,size=skip_connection.shape[2:])\n",
        "        concat_skip=torch.cat((skip_connection,x),dim=1)\n",
        "        x=self.ups[idx+1](concat_skip)\n",
        "    return self.final_conv(x)\n",
        "    # inc=self.inc(x)\n",
        "    # d1=self.down1(inc)\n",
        "    # d2=self.down2(d1)\n",
        "    # d3=self.down3(d2)\n",
        "    # d4=self.down4(d3)\n",
        "\n",
        "    # x=self.up1(d4,d3)\n",
        "    # x=self.up2(x,d2)\n",
        "    # x=self.up3(x,d1)\n",
        "    # x=self.up4(x,inc)\n",
        "    # x=self.conv(x)\n",
        "    # return x\n",
        "\n",
        "def test():\n",
        "   x=torch.randn((3,1,161,161)) \n",
        "   model=Unet(in_channels=1,out_channels=1)\n",
        "   preds=model(x)\n",
        "   assert preds.shape==x.shape\n",
        "\n",
        "if __name__== \"__main__\":\n",
        "  test()\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "#   in_img=torch.randn(1,3,640,640)\n",
        "#   model=Unet(3,5)\n",
        "#   prediction=model(in_img)\n",
        "#   print(prediction.size())\n",
        "\n"
      ],
      "metadata": {
        "id": "pES64fDkKTGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lri8fdx_MTfF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}